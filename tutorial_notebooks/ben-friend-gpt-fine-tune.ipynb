{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Ben Needs a Friend - Fine-tuning GPT3.5\n","This is part of the \"Ben Needs a Friend\" tutorial.  See all the notebooks and materials [here](https://github.com/bpben/ben_friend).\n","\n","Here we walk through a simple example of how to fine-tune GPT 3.5 on a corpus of dialogue from the TV show Friends.  This can be run locally or on Colab, but requires you to have access to [OpenAI's API](https://openai.com/blog/openai-api). \n","\n","Note - use of the API is available for free trial, but is paid after that.\n","\n","This notebook is meant for demonstration, it will require a few steps"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:18:23.225937Z","iopub.status.busy":"2024-04-08T01:18:23.225197Z","iopub.status.idle":"2024-04-08T01:18:40.338152Z","shell.execute_reply":"2024-04-08T01:18:40.336500Z","shell.execute_reply.started":"2024-04-08T01:18:23.225900Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install --quiet openai==1.14.2"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:18:40.341653Z","iopub.status.busy":"2024-04-08T01:18:40.340664Z","iopub.status.idle":"2024-04-08T01:18:42.710437Z","shell.execute_reply":"2024-04-08T01:18:42.709152Z","shell.execute_reply.started":"2024-04-08T01:18:40.341616Z"},"trusted":true},"outputs":[],"source":["import json\n","import pandas as pd\n","from openai import OpenAI"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:18:42.712867Z","iopub.status.busy":"2024-04-08T01:18:42.712321Z","iopub.status.idle":"2024-04-08T01:18:42.720445Z","shell.execute_reply":"2024-04-08T01:18:42.716866Z","shell.execute_reply.started":"2024-04-08T01:18:42.712835Z"},"trusted":true},"outputs":[],"source":["# this is my local way of loading the credential, you will need a .env file with the following:\n","# useful tool for loading .env file with credentials\n","# %pip install --quiet python-dotenv==1.0.1 \n","# from dotenv import load_dotenv\n","# OPENAI_API_KEY=<your key>\n","#load_dotenv('..')\n","#client = OpenAI()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:18:42.723955Z","iopub.status.busy":"2024-04-08T01:18:42.722872Z","iopub.status.idle":"2024-04-08T01:18:42.961170Z","shell.execute_reply":"2024-04-08T01:18:42.959674Z","shell.execute_reply.started":"2024-04-08T01:18:42.723921Z"},"trusted":true},"outputs":[],"source":["# for use in the Kaggle notebook\n","# you will need to access \"Secrets\" under the \"Add-ons\" menu\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","api_key = user_secrets.get_secret(\"OPENAI_API_KEY\")\n","client = OpenAI(api_key=api_key)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:18:42.963631Z","iopub.status.busy":"2024-04-08T01:18:42.963236Z","iopub.status.idle":"2024-04-08T01:18:42.979253Z","shell.execute_reply":"2024-04-08T01:18:42.977813Z","shell.execute_reply.started":"2024-04-08T01:18:42.963598Z"},"trusted":true},"outputs":[],"source":["# just want dialogue from the \"friends\"\n","# everyone else is kind of irrelevant, honestly\n","main_chars = ['Ross', 'Monica', 'Rachel', 'Chandler', 'Phoebe', 'Joey']\n","\n","def pair_valid_lines(lines):\n","    \"\"\"\n","    Utility function to create pairs of valid lines.\n","\n","    Parameters:\n","    - lines (list): List of lines to be processed.\n","\n","    Returns:\n","    - paired_list (list): List of pairs of valid lines.\n","    \"\"\"\n","    paired_list = []\n","    valid_line = []\n","    \n","    for index, line in enumerate(lines):\n","        if is_valid_line(line):\n","            valid_line.append((index, line))\n","        else:\n","            valid_line = []\n","        if len(valid_line) >= 2:\n","            paired_list.append(valid_line[-2:])\n","        \n","    # Check for the last pair if the last valid item is present\n","    if len(valid_line) >= 2:\n","        paired_list.append(valid_line[-2:])\n","    return paired_list\n","\n","def is_valid_line(line, main_chars=main_chars):\n","    \"\"\"\n","    Check if a line is complete, dialogue and part of the main characters.\n","\n","    Parameters:\n","    - line (str): The line to be checked.\n","    \"\"\"\n","    if len(line)>0:\n","        if line[0].isalpha():\n","            name = line.split(':')[0]\n","            if name in main_chars:\n","                return True\n","    return False\n","\n","def run_prompt_exp(prompt, client=client, model='gpt-3.5-turbo'):\n","    \"\"\"\n","    Generate a response using OpenAI's Chat Completions API based on the provided prompt.\n","\n","    Parameters:\n","    - prompt (str): The input prompt for generating a response.\n","    - client (OpenAI API client, optional): The OpenAI API client. Defaults to a pre-defined client.\n","    - model (str, optional): The GPT model to use. Defaults to 'gpt-3.5-turbo'.\n","    \"\"\"\n","    output = {}\n","    output['prompt'] = prompt\n","    completion = client.chat.completions.create(\n","        model=model,\n","        messages=[{\"role\":\"user\",\n","                  \"content\": prompt}])\n","    output['response'] = completion.choices[0].message.model_dump()\n","    output['model'] = completion.model\n","    print(output['response']['content'])\n"]},{"cell_type":"markdown","metadata":{},"source":["### Unfriendly-GPT\n","We create here a \"system prompt\" to give the bot some direction on how to respond.  Then we give it a kind of basic prompt we might ask one of our friends.  We see the base GPT is...kind of a jerk."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:18:42.981731Z","iopub.status.busy":"2024-04-08T01:18:42.981321Z","iopub.status.idle":"2024-04-08T01:18:42.993556Z","shell.execute_reply":"2024-04-08T01:18:42.992572Z","shell.execute_reply.started":"2024-04-08T01:18:42.981693Z"},"trusted":true},"outputs":[],"source":["system_prompt = \"\"\"Your name is Friend.  You are having a conversation with your close friend Ben. \\\n","You and Ben are sarcastic and poke fun at one another. \\\n","But you care about each other and support one another. \\\n","You will be presented with something Ben said. \\\n","Respond as Friend.\"\"\"\n","\n","input_prompt = \"What should we do tonight?\""]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:18:42.996204Z","iopub.status.busy":"2024-04-08T01:18:42.995316Z","iopub.status.idle":"2024-04-08T01:18:43.834657Z","shell.execute_reply":"2024-04-08T01:18:43.833477Z","shell.execute_reply.started":"2024-04-08T01:18:42.996170Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Friend: I know, let's just sit on the couch and watch paint dry. That sounds like a thrilling Friday night plan, Ben.\n"]}],"source":["# how does this look in the base model\n","run_prompt_exp(f\"{system_prompt}\\n{input_prompt}\")"]},{"cell_type":"markdown","metadata":{},"source":["I wouldn't want to be friends with GPT 3.5.\n","\n","But I would like to be friends with Ross, Rachel and the gang!\n","\n","### Friends-ly data\n","Here we format the data to play nice with OpenAI's fine-tuning process.  Were going to treat each exchange between characters as an input/output pair with the system prompt provided above."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:19:18.677955Z","iopub.status.busy":"2024-04-08T01:19:18.677509Z","iopub.status.idle":"2024-04-08T01:19:19.084737Z","shell.execute_reply":"2024-04-08T01:19:19.083552Z","shell.execute_reply.started":"2024-04-08T01:19:18.677921Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["THE ONE WHERE MONICA GETS A NEW ROOMATE (THE PILOT-THE UNCUT VERSION)\n","[(3, \"Monica: There's nothing to tell! He's just some guy I work with!\"), (4, \"Joey: C'mon, you're going out with the guy! There's gotta be something wrong with him!\")]\n"]}],"source":["# you can download this here: https://www.kaggle.com/datasets/divyansh22/friends-tv-show-script?resource=download\n","filepath = '/kaggle/input/friends-tv-show-script/Friends_Transcript.txt'\n","transcript_file = open(filepath, 'r')\n","\n","transcript = transcript_file.read()\n","# split into individual lines\n","lines = transcript.split('\\n')\n","print(lines[0])\n","\n","# pair the valid lines\n","paired_lines = pair_valid_lines(lines)\n","print(paired_lines[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:19:23.491253Z","iopub.status.busy":"2024-04-08T01:19:23.490807Z","iopub.status.idle":"2024-04-08T01:19:23.819189Z","shell.execute_reply":"2024-04-08T01:19:23.817600Z","shell.execute_reply.started":"2024-04-08T01:19:23.491221Z"},"trusted":true},"outputs":[],"source":["# reorganize into OpenAI's format for fine-tuning\n","all_examples = []\n","for a, b in paired_lines:\n","    a_text = a[1].split(': ')[-1]\n","    b_text = b[1].split(': ')[-1]\n","    example = {\n","        \"messages\": [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": a_text}, \n","        {\"role\": \"assistant\", \"content\": b_text}]}\n","    all_examples.append(example)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:19:32.759333Z","iopub.status.busy":"2024-04-08T01:19:32.758940Z","iopub.status.idle":"2024-04-08T01:19:34.248046Z","shell.execute_reply":"2024-04-08T01:19:34.246733Z","shell.execute_reply.started":"2024-04-08T01:19:32.759304Z"},"trusted":true},"outputs":[],"source":["# write examples to file for upload\n","examples_file = 'friends_lines_examples.jsonl'\n","with open(examples_file, 'w') as f:\n","    for ex in all_examples:\n","        json.dump(ex, f)\n","        f.write('\\n')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:19:40.225106Z","iopub.status.busy":"2024-04-08T01:19:40.224478Z","iopub.status.idle":"2024-04-08T01:19:40.230816Z","shell.execute_reply":"2024-04-08T01:19:40.229682Z","shell.execute_reply.started":"2024-04-08T01:19:40.225075Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'messages': [{'role': 'system', 'content': 'Your name is Friend.  You are having a conversation with your close friend Ben. You and Ben are sarcastic and poke fun at one another. But you care about each other and support one another. You will be presented with something Ben said. Respond as Friend.'}, {'role': 'user', 'content': \"There's nothing to tell! He's just some guy I work with!\"}, {'role': 'assistant', 'content': \"C'mon, you're going out with the guy! There's gotta be something wrong with him!\"}]}\n"]}],"source":["print(all_examples[0])"]},{"cell_type":"markdown","metadata":{},"source":["Great! Looks good, now we can move on to trying to fine-tune GPT.  I'm going to limit the dataset a bit - the docs say minimally 50 examples should see improved quality, so let's go with that.  Then we'll see how the fine-tuned model compares to vanilla GPT.\n","\n","There's a few steps to this process, all of it essentially comes from the [OpenAI docs](https://platform.openai.com/docs/guides/fine-tuning)."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:19:48.867565Z","iopub.status.busy":"2024-04-08T01:19:48.867107Z","iopub.status.idle":"2024-04-08T01:19:48.878813Z","shell.execute_reply":"2024-04-08T01:19:48.877307Z","shell.execute_reply.started":"2024-04-08T01:19:48.867530Z"},"trusted":true},"outputs":[],"source":["# subset the data, save down for use\n","n_examples = 50\n","subset_examples = all_examples[:n_examples]\n","subset_examples_file = 'subset_friends_lines_examples.jsonl'\n","with open(subset_examples_file, 'w') as f:\n","    for ex in subset_examples:\n","        json.dump(ex, f)\n","        f.write('\\n')"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning with OpenAI\n","A lot of this just comes from the [documentation](https://platform.openai.com/docs/guides/fine-tuning) on this process.  We need to upload the file, create a fine-tuning job, wait for that to finish and then we have new friend!"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":["openai_file = client.files.create(\n","  file=open(subset_examples_file, \"rb\"),\n","  purpose=\"fine-tune\"\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:20:02.680163Z","iopub.status.busy":"2024-04-08T01:20:02.679711Z","iopub.status.idle":"2024-04-08T01:20:02.963915Z","shell.execute_reply":"2024-04-08T01:20:02.962560Z","shell.execute_reply.started":"2024-04-08T01:20:02.680131Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["File id for subset_friends_lines_examples.jsonl: file-AGKTOBGbhcoU7ETRutOxT7VT\n"]}],"source":["# on creation, we get the file id, but we can also retrieve it \n","training_file = subset_examples_file.split('/')[-1]\n","for f in client.files.list():\n","    if f.filename == training_file:\n","        training_file_id = f.id\n","print(f'File id for {training_file}: {f.id}')\n","        \n","# base model gpt 3.5\n","base_model = \"gpt-3.5-turbo\"\n","# hyperparameters - 3 epochs seems to be a bit more sensible than just 1\n","hyperparameters = {'n_epochs': 3}"]},{"cell_type":"code","execution_count":260,"metadata":{},"outputs":[],"source":["# create the training job\n","ft_job = client.fine_tuning.jobs.create(\n","        training_file=training_file_id, \n","        model=base_model,\n","        hyperparameters=hyperparameters\n","    )"]},{"cell_type":"code","execution_count":262,"metadata":{},"outputs":[{"data":{"text/plain":["'succeeded'"]},"execution_count":262,"metadata":{},"output_type":"execute_result"}],"source":["# can track this id until the job is completed\n","def check_status(job_id):\n","    return client.fine_tuning.jobs.retrieve(job_id).status\n","check_status(ft_job.id)"]},{"cell_type":"markdown","metadata":{},"source":["Eventually, the status will change to \"succeeded\".  Then we get the id of our shiny new fine-tuned model."]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:24:12.115659Z","iopub.status.busy":"2024-04-08T01:24:12.114465Z","iopub.status.idle":"2024-04-08T01:24:12.324462Z","shell.execute_reply":"2024-04-08T01:24:12.323385Z","shell.execute_reply.started":"2024-04-08T01:24:12.115608Z"},"trusted":true},"outputs":[],"source":["# can get this from the job id or we can just get the latest\n","#ft_model_id = client.fine_tuning.jobs.retrieve(ft_job.id).fine_tuned_model\n","finished_at = 0 \n","for f in client.fine_tuning.jobs.list():\n","    if f.status=='succeeded':\n","        # most recent\n","        if f.finished_at>finished_at:\n","            finished_at = f.finished_at\n","            ft_model_id = f.fine_tuned_model"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T01:24:15.013544Z","iopub.status.busy":"2024-04-08T01:24:15.013192Z","iopub.status.idle":"2024-04-08T01:24:18.532984Z","shell.execute_reply":"2024-04-08T01:24:18.531434Z","shell.execute_reply.started":"2024-04-08T01:24:15.013516Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Well, we could go to the coffeehouse and then hit the town.\n"]}],"source":["prompt = \"What are we doing tonight?\"\n","run_prompt_exp(f\"{system_prompt}\\n{prompt}\",\n","              model=ft_model_id)"]},{"cell_type":"markdown","metadata":{},"source":["If your result is anything like mine, you too will wonder why GPT is all about Ross.  He's like the worst character."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":772761,"sourceId":1331278,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"llamabot","language":"python","name":"llamabot"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":5}
