{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ben Needs a Friend - LLM Agent for event listings\nThis is part of the \"Ben Needs a Friend\" tutorial.  See all the notebooks and materials [here](https://github.com/bpben/ben_friend).\n\nThis notebook is intended to be run in Kaggle Notebooks.  Access that version [here](https://www.kaggle.com/code/bpoben/ben-needs-a-friend-llm-agent). \n\nIn this notebook, we set up a simple workflow for an agent to suggest some cool events from the [Boston Calendar](https://www.thebostoncalendar.com/).  This can be run locally or on Kaggle, but requires you to have access to [OpenAI's API](https://openai.com/blog/openai-api). ","metadata":{}},{"cell_type":"code","source":"# install requirements (required for Kaggle setup)\n%pip install -q langchain langchain_openai\n# only if you plan to use the HF setup here\n#%pip install -q bitsandbytes accelerate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain.agents import (\n    tool, \n    create_react_agent,\n    AgentExecutor\n)\nfrom langchain_core.prompts import PromptTemplate\nfrom datetime import datetime, date\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers.string import StrOutputParser\nfrom langchain.tools.render import render_text_description\n\n# this is for simple scraping tool\nimport requests\nfrom random import sample\nfrom bs4 import BeautifulSoup","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting up the agent\nHere are three ways for setting up your LLM.  For more details, see the README! \n\n1) OpenAI GPT 3.5 - Requires an API key (not free!) You will also need to have an .env file that looks like: `OPENAI_API_KEY=<API key>`\n\n2) Ollama - See the README for setup instructions.  Only tested with Mac M1 OS.\n\n3) Mistral + Kaggle notebook - Designed for use of free GPU, will need installation of packages above.","metadata":{}},{"cell_type":"code","source":"# setting up GPT-3.5 configuration\n# # using .env file for GPT API key\n# from dotenv import load_dotenv\n# load_dotenv()\n# llm_model = \"gpt-3.5-turbo\"\n# openai = ChatOpenAI(model=llm_model)\n\n# for use in the Kaggle notebook\n# you will need to access \"Secrets\" under the \"Add-ons\" menu\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"OPENAI_API_KEY\")\nllm_model = \"gpt-3.5-turbo\"\nopenai = ChatOpenAI(api_key=api_key, model=llm_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# running with local Ollama\n# see setup instructions - this is different from use in Kaggle\nfrom langchain.llms import Ollama\nollama_instruct_model = 'mistral'\n\n# load pre-trained model\nollama = Ollama(model=ollama_instruct_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# running with Mistral in Kaggle notebook\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom transformers import BitsAndBytesConfig\nfrom langchain_community.llms import HuggingFacePipeline\nmodel_name = '/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'\n\n# Configure quantization\nquantization_config = BitsAndBytesConfig(load_in_4bit=True)\n\n# will use HF's pipeline and LC's wrapping\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n                                            device_map='auto',# makes use of the GPUs\n                                            quantization_config=quantization_config, # for speed/memory\n                                            )\npipe = pipeline(\"text-generation\", \n                model=model, tokenizer=tokenizer,\n                max_new_tokens=20, # arbitrary, for short answers\n               device_map='auto',)\n\nhf_pipe = HuggingFacePipeline(pipeline=pipe)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choose your own adventure - for consistency on the llm we'll be using\nllm = openai","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Early experiments with agents\n\nIf we ask our model to tell us the day, it's not particularly useful.  It has no knowledge of the current date!","metadata":{}},{"cell_type":"code","source":"print(llm.invoke('What day is it today?').content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" But if we design a function and provided the details to the model, it can suggest what steps to take to get the information it needs.\n\n We'll use LangChain's capability here.  The `@tool` decorator wraps the function that makes it easier to process the text description into input into the model.","metadata":{}},{"cell_type":"code","source":"# notice the detailed docstrings - this is to allow the LLM to understand its purpose\n# this is a tool decorator for LangChain, it enables it to be parsed \n@tool\ndef today(text: str) -> str:\n    \"\"\"Returns today's date, use this when you need to get today's date.\\\n    The input should always be an empty string.\"\"\"\n    return str(date.today())\n\n# render the tool for a prompt (requires input as a list)\nrender_text_description([today])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Try it: Construct a tool-aware prompt\nThe previous examples with LC should give us some idea how we might plug this tool description into the LLM input so it knows the tool is available.  An example is provided below.","metadata":{}},{"cell_type":"code","source":"template = \"\"\"Answer the following questions as best you can. \\\nYou will need to break your response into steps, each which may use a different tool. \\\nYou have access to the following tools:\n\n{tools}\n\nQuestion: {input}\n\"\"\"\n\nprompt = PromptTemplate.from_template(template)\n\nchain = prompt | llm | StrOutputParser()\n\nresponse = chain.invoke(input={\n    \"input\": \"What day is it today?\",\n    \"tools\": [today]\n    })\nprint(response)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting up the Reasoning + Act (ReAct) prompt\nThis is an adapted version of [LangChain's example](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html).  It provides a structure for the model to generate its outputs as well as placeholders for the tool descriptions and names.\n\nThe \"scratchpad\" is essentially the model's \"memory; where all the things its thought and done will be entered.\n","metadata":{}},{"cell_type":"code","source":"# prompt is adapted from LangChain's example: https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html\n# action input is required to be a string - otherwise I found it would use function calls as inputs\ntemplate = '''You will be a answering questions about upcoming events. \\\nYou will need to break your response into steps, each which may use a different tool. \\\nYou have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: an input to the action, usually an empty string\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question. \n\nThink step by step! Begin!\n\nQuestion: {input}\nThought:{agent_scratchpad}'''\n\nprompt = PromptTemplate.from_template(template)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Simple workflow\nLC has its own implementation of the ReAct framework.  When you call `create_react_agent`, it will create a pipe with several components.  Let's look at those components:","metadata":{}},{"cell_type":"code","source":"# copying this here for reference\n@tool\ndef today(text: str) -> str:\n    \"\"\"Returns today's date, use this when you need to get today's date.\n    The input should always be an empty string.\"\"\"\n    return str(date.today())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tools = [today]\nagent = create_react_agent(llm, tools, prompt)\nfor stage, component in agent:\n    if component is not None:\n        print(stage)\n        if stage=='middle':\n            for c in component:\n                print(c)\n                print('--')\n        else:\n            print(component.__repr__())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Step by step through the chain above:\n- First: The `format_log_to_str` takes the steps that have been performed so far (i.e. thoughts + actions) and formats them into the model input\n- Middle\n  - First is the prompt, which has \"partial variables\" corresponding to the tools with passed it.  These will be populated in the tools an tool_names fields in the prompt when the agent runs\n  - Then, we have the model itself\n    - Note here - there is a \"stop\" argument - this tells the agent workflow when to stop, so that actions can be parsed \n- Last: The \"output parser\" which parses the tools and the parameters\n\nAll this gets wrappered in an `AgentExecutor`, which controls the flow through the chain (described above) and actually executes the tools, feeding their output back to the LLM.\n\n`verbose`: Enables us to see all the intermediate steps.  \n`handle_parsing_errors`: Errors in execution will be fed back to the model to see if it can correct iself.\n\nYou'll see in green the text produced by the agent and in blue the output from the function.  ","metadata":{}},{"cell_type":"code","source":"# run the agent\nagent_executor = AgentExecutor(agent=agent, tools=tools, \n                               verbose=True, \n                               handle_parsing_errors=True,\n                              max_iterations=5)\nprint(agent_executor.invoke({\"input\": \"What day is it today?\"})['output'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the smaller models, you'll see some weird answers.  With GPT 3.5, you'll usually get the workflow you're looking for.\n\n#### Local events workflow\nThese next functions provide two new tools for our agent; one that provides the current \"weekend number\" in the month and one that scrapes Boston Calendar for event information.  Most of this is just scraping and formatting Boston Calendar, but the functions with the tool decorators will be provided to the model.\n\nThen, we set up our ReAct agent as before.\n\nA note here - this *usually* works with GPT 3.5.  With other models, it's hit and miss.  That's likely due both to the complexity of the task and the fact that LangChain is...[complicated](https://minimaxir.com/2023/07/langchain-problem/) in how it builds these workflows.","metadata":{}},{"cell_type":"code","source":"\ndef parse_for_calendar(text: str) -> str:\n    # utility for converting text input to boston calendar URL\n    if len(text) == 1:\n        # will assume today's month if we're looking at weekend number\n        today = datetime.now()\n        month = today.month\n        day = today.day\n        url = f'https://www.thebostoncalendar.com/events?day={day}&month={month}&weekend={text}&year=2024'\n    # this will fail if the string provided is not a date\n    else:\n        try:\n            f_date = datetime.strptime(text, '%Y-%M-%d')\n            day_of_month = f_date.day\n            month = f_date.month\n            url = f'https://www.thebostoncalendar.com/events?day={day_of_month}&month={month}&year=2024'\n        except ValueError:\n            return \n    return url\n\n@tool\ndef weekend(text: str) -> str:\n    \"\"\"Returns the single-digit weekend number for this weekend, \\\n    use this for any questions related to the weekend date. \\\n    The input should always be an empty string, \\\n    and this function will always return the weekend number.\"\"\"\n    today = datetime.now()\n    \n    # Calculate the weekend number within the month\n    first_day_of_month = today.replace(day=1)\n    weekend_number_within_month = (today - first_day_of_month).days // 7 + 1\n\n    return weekend_number_within_month\n\n@tool\ndef get_events(text: str) -> str:\n    \"\"\"Returns information about local events. \\ \n    The input is either a date string in the format YYYY-MM-DD, \\\n    or it is a single-digit weekend number.\\\n    This function will return a list where \\\n    each element contains an event name, date and location as a tuple.\\\n    This function should be used to provide complete information about events.\"\"\"\n    # use the parsing utility to get a formatted url\n    url = parse_for_calendar(text)\n    if url is None:\n        # give the LLM a useful response\n        return f'Input \"{text}\" is not in the right format - it needs to be a date string or a weekend number'\n    response = requests.get(url)     \n    \n    # Parse the HTML content\n    soup = BeautifulSoup(response.content, 'html.parser')\n    \n    # Extract data\n    events = soup.find_all('div', class_='info')\n\n    all_events = []\n    for event in events:\n        title = event.find('h3').text.strip()\n        date = event.find('p', class_='time').text.strip()\n        location = event.find('p', class_='location').text.strip()\n        all_events.append((title, date, location))\n\n    # randomly select a few, provide as list\n    # just reducing the amount of tokens being passed to the model, this gives the idea\n    choices = sample(all_events, 3)\n    \n    return choices\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tools = [today, weekend, get_events]\nagent = create_react_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, \n                               verbose=True, \n                               handle_parsing_errors=True,\n                               max_iterations=5)\nagent_executor.invoke({\"input\": \"What is going on this weekend?\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, using the smaller models will yield weird results, but GPT is usually able to do this successfully.\n\nWe can see here that the output provides three random examples of events coming up this weekend.  One note - if you run this during the weekend, it will return information for the current weekend.\n\nOur \"today\" tool also enables the agent to get today's events.","metadata":{}},{"cell_type":"code","source":"tools = [today, weekend, get_events]\nagent = create_react_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, \n                               verbose=True, \n                               handle_parsing_errors=True,\n                              max_iterations=5)\nagent_executor.invoke({\"input\": \"What is going on today?\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we can even ask for specific dates!","metadata":{}},{"cell_type":"code","source":"agent_executor.invoke({\"input\": \"What is going on 4/28/24?\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \"Friendly\" style\nIn the above example, we get a sort of generic tone in our response.  Our Friend would never talk like that, would they?\n\n\n#### Try it: Make the response more friendly\nTry and use what you know so far to come up with a way to make the output more in the style of the Friend we designed.\n\nThere's a couple ways to do this\n\n1) Edit the ReAct prompt to generate something more friendly\n\n2) Pipe the output of the agent flow into a \"styling\" prompt.\n","metadata":{}},{"cell_type":"code","source":"# \"friendly\" version of the ReAct prompt\nfriend_template = '''Answer the following questions as best you can. \\\nYou will need to break your response into steps, each which may use a different tool. \\\nYou have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: an input to the action, usually an empty string\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question. \nOutput the final answer as if you're having a fun conversation with a good friend.\n\nThink step by step! Begin!\n\nQuestion: {input}\nThought:{agent_scratchpad}'''\n\nfriend_prompt = PromptTemplate.from_template(friend_template)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agent = create_react_agent(llm, tools, friend_prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, \n                               verbose=True, \n                               handle_parsing_errors=True,\n                              max_iterations=5)\nagent_executor.invoke({\"input\": \"What is going on today?\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sometimes this will confuse the flow and you may have less success even with GPT.  With the smaller models, it definitely becomes a challenge.  Another way to get a friendly response would be to do a separate \"rewrite\" call. ","metadata":{}},{"cell_type":"code","source":"# creating a styling prompt\nstyling_prompt = \"\"\"Your name is Friend.  You are having a conversation with your close friend Ben. \nYou and Ben are sarcastic and poke fun at one another. \nBut you care about each other and support one another.\n\nYou know the following information:\n{events_output}\n\nBen: {input}\nProvide your response:\"\"\"\n\nstyling_template = PromptTemplate.from_template(styling_prompt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nstyling_agent = {'events_output': agent_executor, 'input': RunnablePassthrough()} | \\\nstyling_template | llm | StrOutputParser()\n\nprint(styling_agent.invoke({\"input\": \"What is going on today?\"}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}